{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\01din\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This was also more of an experiment where I wanted to get more familiar with w2v and the dataset. Nothing very useful was made here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "generic = lambda x: literal_eval(x)\n",
    "conv = {'nutrition' : generic, 'steps' : generic, 'ingredients' : generic, 'tags' : generic}\n",
    "df = pd.read_csv('C:/Users/01din\\Documents/University\\BSc thesis\\data\\RAW_recipes.csv\\RAW\\RAW_recipes.csv', converters=conv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ' '.join(char if char not in string.punctuation else ' ' for char in text)\n",
    "\n",
    "def preprocess_ingredients(ingredients_list):\n",
    "    preprocessed = []\n",
    "    for ingredient in ingredients_list:\n",
    "        words = ingredient.split()\n",
    "        if len(words) > 1:\n",
    "            preprocessed.append('_'.join(words))\n",
    "        else:\n",
    "            preprocessed.append(ingredient)\n",
    "    return preprocessed\n",
    "\n",
    "def replace_multiword_ingredients(instruction, ingredient_list):\n",
    "    for ingredient in ingredient_list:\n",
    "        words = ingredient.split()\n",
    "        if len(words) > 1:\n",
    "            underscored_ingredient = '_'.join(words)\n",
    "            instruction = instruction.replace(ingredient, underscored_ingredient)\n",
    "    return instruction\n",
    "\n",
    "ingredients = df.ingredients.tolist()\n",
    "instructions = df.steps.tolist()\n",
    "\n",
    "instructions = [remove_punctuation(instruction) for instruction in instructions]\n",
    "\n",
    "recipes = {'ingredients': ingredients, 'instructions': instructions}\n",
    "\n",
    "preprocessed_ingredients = [preprocess_ingredients(ingredient_list) for ingredient_list in recipes['ingredients']]\n",
    "\n",
    "preprocessed_instructions = []\n",
    "for instruction, ingredient_list in zip(instructions, preprocessed_ingredients):\n",
    "    preprocessed_instructions.append(replace_multiword_ingredients(instruction, ingredient_list))\n",
    "\n",
    "full_text = [ingredients + [instructions] for ingredients, instructions in zip(preprocessed_ingredients, preprocessed_instructions)]\n",
    "full_text = [' '.join(sublist) for sublist in full_text]\n",
    "\n",
    "tokenized_text = [recipe.split() for recipe in full_text]\n",
    "tokenized_text = [[s for s in recipe if s != ','] for recipe in tokenized_text]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "['winter_squash',\n 'mexican_seasoning',\n 'mixed_spice',\n 'honey',\n 'butter',\n 'olive_oil',\n 'salt',\n 'make',\n 'a',\n 'choice',\n 'and',\n 'proceed',\n 'with',\n 'recipe',\n 'depending',\n 'on',\n 'size',\n 'of',\n 'squash',\n 'cut',\n 'into',\n 'half',\n 'or',\n 'fourths',\n 'remove',\n 'seeds',\n 'for',\n 'spicy',\n 'squash',\n 'drizzle',\n 'olive',\n 'oil',\n 'or',\n 'melted',\n 'butter',\n 'over',\n 'each',\n 'cut',\n 'squash',\n 'piece',\n 'season',\n 'with',\n 'mexican',\n 'seasoning',\n 'mix',\n 'ii',\n 'for',\n 'sweet',\n 'squash',\n 'drizzle',\n 'melted',\n 'honey',\n 'butter',\n 'grated',\n 'piloncillo',\n 'over',\n 'each',\n 'cut',\n 'squash',\n 'piece',\n 'season',\n 'with',\n 'sweet',\n 'mexican',\n 'spice',\n 'mix',\n 'bake',\n 'at',\n '350',\n 'degrees',\n 'again',\n 'depending',\n 'on',\n 'size',\n 'for',\n '40',\n 'minutes',\n 'up',\n 'to',\n 'an',\n 'hour',\n 'until',\n 'a',\n 'fork',\n 'can',\n 'easily',\n 'pierce',\n 'the',\n 'skin',\n 'be',\n 'careful',\n 'not',\n 'to',\n 'burn',\n 'the',\n 'squash',\n 'especially',\n 'if',\n 'you',\n 'opt',\n 'to',\n 'use',\n 'sugar',\n 'or',\n 'butter',\n 'if',\n 'you',\n 'feel',\n 'more',\n 'comfortable',\n 'cover',\n 'the',\n 'squash',\n 'with',\n 'aluminum',\n 'foil',\n 'the',\n 'first',\n 'half',\n 'hour',\n 'give',\n 'or',\n 'take',\n 'of',\n 'baking',\n 'if',\n 'desired',\n 'season',\n 'with',\n 'salt']"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 04:33:07,306 : INFO : collecting all words and their counts\n",
      "2023-04-14 04:33:07,308 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-14 04:33:07,453 : INFO : PROGRESS: at sentence #10000, processed 1046736 words, keeping 17892 word types\n",
      "2023-04-14 04:33:07,561 : INFO : PROGRESS: at sentence #20000, processed 2082452 words, keeping 24744 word types\n",
      "2023-04-14 04:33:07,667 : INFO : PROGRESS: at sentence #30000, processed 3152956 words, keeping 30079 word types\n",
      "2023-04-14 04:33:07,773 : INFO : PROGRESS: at sentence #40000, processed 4213730 words, keeping 34763 word types\n",
      "2023-04-14 04:33:07,886 : INFO : PROGRESS: at sentence #50000, processed 5353583 words, keeping 38513 word types\n",
      "2023-04-14 04:33:07,993 : INFO : PROGRESS: at sentence #60000, processed 6429441 words, keeping 42381 word types\n",
      "2023-04-14 04:33:08,096 : INFO : PROGRESS: at sentence #70000, processed 7400876 words, keeping 45240 word types\n",
      "2023-04-14 04:33:08,195 : INFO : PROGRESS: at sentence #80000, processed 8381776 words, keeping 48542 word types\n",
      "2023-04-14 04:33:08,301 : INFO : PROGRESS: at sentence #90000, processed 9448592 words, keeping 52093 word types\n",
      "2023-04-14 04:33:08,405 : INFO : PROGRESS: at sentence #100000, processed 10498590 words, keeping 54914 word types\n",
      "2023-04-14 04:33:08,506 : INFO : PROGRESS: at sentence #110000, processed 11508245 words, keeping 57858 word types\n",
      "2023-04-14 04:33:08,614 : INFO : PROGRESS: at sentence #120000, processed 12597566 words, keeping 60994 word types\n",
      "2023-04-14 04:33:08,717 : INFO : PROGRESS: at sentence #130000, processed 13639550 words, keeping 63530 word types\n",
      "2023-04-14 04:33:08,822 : INFO : PROGRESS: at sentence #140000, processed 14690034 words, keeping 66030 word types\n",
      "2023-04-14 04:33:08,925 : INFO : PROGRESS: at sentence #150000, processed 15721479 words, keeping 68575 word types\n",
      "2023-04-14 04:33:09,031 : INFO : PROGRESS: at sentence #160000, processed 16787278 words, keeping 70880 word types\n",
      "2023-04-14 04:33:09,140 : INFO : PROGRESS: at sentence #170000, processed 17868850 words, keeping 73109 word types\n",
      "2023-04-14 04:33:09,248 : INFO : PROGRESS: at sentence #180000, processed 18974318 words, keeping 75589 word types\n",
      "2023-04-14 04:33:09,355 : INFO : PROGRESS: at sentence #190000, processed 20023387 words, keeping 77624 word types\n",
      "2023-04-14 04:33:09,462 : INFO : PROGRESS: at sentence #200000, processed 21097461 words, keeping 79610 word types\n",
      "2023-04-14 04:33:09,564 : INFO : PROGRESS: at sentence #210000, processed 22116014 words, keeping 81540 word types\n",
      "2023-04-14 04:33:09,676 : INFO : PROGRESS: at sentence #220000, processed 23246911 words, keeping 83989 word types\n",
      "2023-04-14 04:33:09,780 : INFO : PROGRESS: at sentence #230000, processed 24300603 words, keeping 86014 word types\n",
      "2023-04-14 04:33:09,797 : INFO : collected 86314 word types from a corpus of 24464085 raw words and 231637 sentences\n",
      "2023-04-14 04:33:09,798 : INFO : Creating a fresh vocabulary\n",
      "2023-04-14 04:33:09,973 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 86314 unique words (100.00% of original 86314, drops 0)', 'datetime': '2023-04-14T04:33:09.973835', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-14 04:33:09,974 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 24464085 word corpus (100.00% of original 24464085, drops 0)', 'datetime': '2023-04-14T04:33:09.974836', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-14 04:33:10,236 : INFO : deleting the raw counts dictionary of 86314 items\n",
      "2023-04-14 04:33:10,238 : INFO : sample=0.001 downsamples 61 most-common words\n",
      "2023-04-14 04:33:10,239 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 18308089.76428523 word corpus (74.8%% of prior 24464085)', 'datetime': '2023-04-14T04:33:10.239146', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-04-14 04:33:10,713 : INFO : estimated required memory for 86314 words and 100 dimensions: 112208200 bytes\n",
      "2023-04-14 04:33:10,714 : INFO : resetting layer weights\n",
      "2023-04-14 04:33:10,744 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-14T04:33:10.744269', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2023-04-14 04:33:10,745 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 86314 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-14T04:33:10.745268', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-14 04:33:11,865 : INFO : EPOCH 0 - PROGRESS: at 18.31% examples, 3338302 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:12,866 : INFO : EPOCH 0 - PROGRESS: at 37.33% examples, 3402754 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:13,868 : INFO : EPOCH 0 - PROGRESS: at 56.56% examples, 3425623 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:14,869 : INFO : EPOCH 0 - PROGRESS: at 75.49% examples, 3438281 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:15,868 : INFO : EPOCH 0 - PROGRESS: at 94.45% examples, 3451848 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:16,162 : INFO : EPOCH 0: training on 24464085 raw words (18307745 effective words) took 5.3s, 3455270 effective words/s\n",
      "2023-04-14 04:33:17,168 : INFO : EPOCH 1 - PROGRESS: at 18.31% examples, 3329649 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:18,172 : INFO : EPOCH 1 - PROGRESS: at 37.42% examples, 3401422 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:19,173 : INFO : EPOCH 1 - PROGRESS: at 56.51% examples, 3417674 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:20,176 : INFO : EPOCH 1 - PROGRESS: at 75.49% examples, 3432859 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:21,181 : INFO : EPOCH 1 - PROGRESS: at 94.10% examples, 3430916 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:21,494 : INFO : EPOCH 1: training on 24464085 raw words (18308424 effective words) took 5.3s, 3435016 effective words/s\n",
      "2023-04-14 04:33:22,498 : INFO : EPOCH 2 - PROGRESS: at 18.77% examples, 3430500 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:23,498 : INFO : EPOCH 2 - PROGRESS: at 37.91% examples, 3455329 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:24,502 : INFO : EPOCH 2 - PROGRESS: at 57.14% examples, 3461098 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:25,502 : INFO : EPOCH 2 - PROGRESS: at 76.09% examples, 3468536 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:26,503 : INFO : EPOCH 2 - PROGRESS: at 94.14% examples, 3439193 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:26,823 : INFO : EPOCH 2: training on 24464085 raw words (18307071 effective words) took 5.3s, 3437288 effective words/s\n",
      "2023-04-14 04:33:27,827 : INFO : EPOCH 3 - PROGRESS: at 18.13% examples, 3301797 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:28,827 : INFO : EPOCH 3 - PROGRESS: at 37.09% examples, 3378682 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:29,829 : INFO : EPOCH 3 - PROGRESS: at 56.37% examples, 3416022 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:30,829 : INFO : EPOCH 3 - PROGRESS: at 75.44% examples, 3435410 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:31,830 : INFO : EPOCH 3 - PROGRESS: at 94.41% examples, 3450655 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:32,130 : INFO : EPOCH 3: training on 24464085 raw words (18308792 effective words) took 5.3s, 3451381 effective words/s\n",
      "2023-04-14 04:33:33,135 : INFO : EPOCH 4 - PROGRESS: at 18.60% examples, 3390721 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:34,137 : INFO : EPOCH 4 - PROGRESS: at 37.80% examples, 3439693 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:35,138 : INFO : EPOCH 4 - PROGRESS: at 57.11% examples, 3457839 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:36,139 : INFO : EPOCH 4 - PROGRESS: at 76.09% examples, 3467494 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:37,141 : INFO : EPOCH 4 - PROGRESS: at 95.15% examples, 3480419 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:37,395 : INFO : EPOCH 4: training on 24464085 raw words (18308496 effective words) took 5.3s, 3478439 effective words/s\n",
      "2023-04-14 04:33:38,398 : INFO : EPOCH 5 - PROGRESS: at 18.56% examples, 3391844 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:39,399 : INFO : EPOCH 5 - PROGRESS: at 37.76% examples, 3441223 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:40,399 : INFO : EPOCH 5 - PROGRESS: at 55.80% examples, 3385866 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:41,400 : INFO : EPOCH 5 - PROGRESS: at 74.71% examples, 3401697 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:42,402 : INFO : EPOCH 5 - PROGRESS: at 93.90% examples, 3432013 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:42,730 : INFO : EPOCH 5: training on 24464085 raw words (18308095 effective words) took 5.3s, 3433439 effective words/s\n",
      "2023-04-14 04:33:43,733 : INFO : EPOCH 6 - PROGRESS: at 18.35% examples, 3348137 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:44,734 : INFO : EPOCH 6 - PROGRESS: at 37.38% examples, 3407907 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:45,735 : INFO : EPOCH 6 - PROGRESS: at 56.79% examples, 3442590 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:46,736 : INFO : EPOCH 6 - PROGRESS: at 75.98% examples, 3465539 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:47,738 : INFO : EPOCH 6 - PROGRESS: at 94.75% examples, 3465056 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:48,010 : INFO : EPOCH 6: training on 24464085 raw words (18310910 effective words) took 5.3s, 3469279 effective words/s\n",
      "2023-04-14 04:33:49,013 : INFO : EPOCH 7 - PROGRESS: at 18.49% examples, 3377795 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:50,014 : INFO : EPOCH 7 - PROGRESS: at 37.72% examples, 3437907 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:51,016 : INFO : EPOCH 7 - PROGRESS: at 57.11% examples, 3461492 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:52,018 : INFO : EPOCH 7 - PROGRESS: at 76.01% examples, 3465294 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:53,018 : INFO : EPOCH 7 - PROGRESS: at 94.75% examples, 3464956 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:53,288 : INFO : EPOCH 7: training on 24464085 raw words (18308613 effective words) took 5.3s, 3470694 effective words/s\n",
      "2023-04-14 04:33:54,291 : INFO : EPOCH 8 - PROGRESS: at 18.80% examples, 3441835 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:55,292 : INFO : EPOCH 8 - PROGRESS: at 38.07% examples, 3470307 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:56,294 : INFO : EPOCH 8 - PROGRESS: at 57.44% examples, 3483179 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:57,296 : INFO : EPOCH 8 - PROGRESS: at 76.56% examples, 3491227 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:58,300 : INFO : EPOCH 8 - PROGRESS: at 95.57% examples, 3496054 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:33:58,528 : INFO : EPOCH 8: training on 24464085 raw words (18310227 effective words) took 5.2s, 3495745 effective words/s\n",
      "2023-04-14 04:33:59,532 : INFO : EPOCH 9 - PROGRESS: at 18.77% examples, 3431823 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:00,532 : INFO : EPOCH 9 - PROGRESS: at 38.03% examples, 3465890 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:01,533 : INFO : EPOCH 9 - PROGRESS: at 57.36% examples, 3477484 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:02,536 : INFO : EPOCH 9 - PROGRESS: at 76.28% examples, 3478373 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:03,537 : INFO : EPOCH 9 - PROGRESS: at 94.64% examples, 3457374 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:03,822 : INFO : EPOCH 9: training on 24464085 raw words (18306162 effective words) took 5.3s, 3459129 effective words/s\n",
      "2023-04-14 04:34:04,826 : INFO : EPOCH 10 - PROGRESS: at 18.13% examples, 3302689 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:05,826 : INFO : EPOCH 10 - PROGRESS: at 36.87% examples, 3356162 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:06,829 : INFO : EPOCH 10 - PROGRESS: at 56.00% examples, 3392572 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:07,831 : INFO : EPOCH 10 - PROGRESS: at 75.37% examples, 3429690 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:08,832 : INFO : EPOCH 10 - PROGRESS: at 94.41% examples, 3449470 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:09,136 : INFO : EPOCH 10: training on 24464085 raw words (18307902 effective words) took 5.3s, 3447073 effective words/s\n",
      "2023-04-14 04:34:10,140 : INFO : EPOCH 11 - PROGRESS: at 18.56% examples, 3387875 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:11,142 : INFO : EPOCH 11 - PROGRESS: at 38.14% examples, 3472365 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:12,144 : INFO : EPOCH 11 - PROGRESS: at 57.40% examples, 3476863 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:13,146 : INFO : EPOCH 11 - PROGRESS: at 76.71% examples, 3497046 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:14,147 : INFO : EPOCH 11 - PROGRESS: at 95.64% examples, 3499881 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:14,365 : INFO : EPOCH 11: training on 24464085 raw words (18308703 effective words) took 5.2s, 3503495 effective words/s\n",
      "2023-04-14 04:34:15,369 : INFO : EPOCH 12 - PROGRESS: at 18.87% examples, 3448085 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:16,369 : INFO : EPOCH 12 - PROGRESS: at 37.95% examples, 3456144 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:17,370 : INFO : EPOCH 12 - PROGRESS: at 57.33% examples, 3474973 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:18,371 : INFO : EPOCH 12 - PROGRESS: at 76.01% examples, 3465684 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:19,371 : INFO : EPOCH 12 - PROGRESS: at 94.91% examples, 3472772 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:19,634 : INFO : EPOCH 12: training on 24464085 raw words (18305590 effective words) took 5.3s, 3475384 effective words/s\n",
      "2023-04-14 04:34:20,637 : INFO : EPOCH 13 - PROGRESS: at 18.53% examples, 3380772 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:21,638 : INFO : EPOCH 13 - PROGRESS: at 37.76% examples, 3440197 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:22,641 : INFO : EPOCH 13 - PROGRESS: at 56.95% examples, 3449416 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:23,641 : INFO : EPOCH 13 - PROGRESS: at 75.86% examples, 3458306 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:24,645 : INFO : EPOCH 13 - PROGRESS: at 94.75% examples, 3462716 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:24,922 : INFO : EPOCH 13: training on 24464085 raw words (18309561 effective words) took 5.3s, 3463511 effective words/s\n",
      "2023-04-14 04:34:25,925 : INFO : EPOCH 14 - PROGRESS: at 18.87% examples, 3455869 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:26,926 : INFO : EPOCH 14 - PROGRESS: at 37.84% examples, 3447830 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:27,928 : INFO : EPOCH 14 - PROGRESS: at 57.56% examples, 3489604 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:28,930 : INFO : EPOCH 14 - PROGRESS: at 76.52% examples, 3490397 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:29,931 : INFO : EPOCH 14 - PROGRESS: at 95.42% examples, 3492862 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:30,165 : INFO : EPOCH 14: training on 24464085 raw words (18309204 effective words) took 5.2s, 3494255 effective words/s\n",
      "2023-04-14 04:34:31,167 : INFO : EPOCH 15 - PROGRESS: at 18.73% examples, 3427430 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:32,167 : INFO : EPOCH 15 - PROGRESS: at 38.14% examples, 3475171 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:33,170 : INFO : EPOCH 15 - PROGRESS: at 57.14% examples, 3463110 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:34,171 : INFO : EPOCH 15 - PROGRESS: at 75.90% examples, 3461123 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:35,171 : INFO : EPOCH 15 - PROGRESS: at 94.70% examples, 3462704 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:35,450 : INFO : EPOCH 15: training on 24464085 raw words (18308045 effective words) took 5.3s, 3465231 effective words/s\n",
      "2023-04-14 04:34:36,453 : INFO : EPOCH 16 - PROGRESS: at 18.63% examples, 3406012 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:37,454 : INFO : EPOCH 16 - PROGRESS: at 37.95% examples, 3460174 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:38,456 : INFO : EPOCH 16 - PROGRESS: at 57.25% examples, 3471530 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:39,456 : INFO : EPOCH 16 - PROGRESS: at 76.52% examples, 3491308 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:40,460 : INFO : EPOCH 16 - PROGRESS: at 95.60% examples, 3499427 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:40,688 : INFO : EPOCH 16: training on 24464085 raw words (18309539 effective words) took 5.2s, 3497122 effective words/s\n",
      "2023-04-14 04:34:41,691 : INFO : EPOCH 17 - PROGRESS: at 18.56% examples, 3389732 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:42,695 : INFO : EPOCH 17 - PROGRESS: at 37.84% examples, 3444680 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:43,695 : INFO : EPOCH 17 - PROGRESS: at 56.00% examples, 3391920 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:44,697 : INFO : EPOCH 17 - PROGRESS: at 74.42% examples, 3384946 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:45,698 : INFO : EPOCH 17 - PROGRESS: at 93.27% examples, 3404638 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:46,059 : INFO : EPOCH 17: training on 24464085 raw words (18306130 effective words) took 5.4s, 3410243 effective words/s\n",
      "2023-04-14 04:34:47,063 : INFO : EPOCH 18 - PROGRESS: at 18.67% examples, 3409390 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:48,065 : INFO : EPOCH 18 - PROGRESS: at 37.95% examples, 3456054 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:49,065 : INFO : EPOCH 18 - PROGRESS: at 57.33% examples, 3475125 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:50,065 : INFO : EPOCH 18 - PROGRESS: at 76.40% examples, 3485061 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:51,067 : INFO : EPOCH 18 - PROGRESS: at 95.38% examples, 3491212 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:51,299 : INFO : EPOCH 18: training on 24464085 raw words (18307486 effective words) took 5.2s, 3494710 effective words/s\n",
      "2023-04-14 04:34:52,303 : INFO : EPOCH 19 - PROGRESS: at 18.42% examples, 3360475 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:53,305 : INFO : EPOCH 19 - PROGRESS: at 37.76% examples, 3439098 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:54,306 : INFO : EPOCH 19 - PROGRESS: at 56.79% examples, 3440317 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:55,307 : INFO : EPOCH 19 - PROGRESS: at 75.79% examples, 3454573 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:56,308 : INFO : EPOCH 19 - PROGRESS: at 94.70% examples, 3462055 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:56,585 : INFO : EPOCH 19: training on 24464085 raw words (18310332 effective words) took 5.3s, 3465962 effective words/s\n",
      "2023-04-14 04:34:57,587 : INFO : EPOCH 20 - PROGRESS: at 18.73% examples, 3427756 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:58,589 : INFO : EPOCH 20 - PROGRESS: at 38.24% examples, 3482196 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:34:59,591 : INFO : EPOCH 20 - PROGRESS: at 57.60% examples, 3493551 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:00,591 : INFO : EPOCH 20 - PROGRESS: at 76.52% examples, 3490192 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:01,592 : INFO : EPOCH 20 - PROGRESS: at 95.42% examples, 3493595 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:01,822 : INFO : EPOCH 20: training on 24464085 raw words (18308238 effective words) took 5.2s, 3497370 effective words/s\n",
      "2023-04-14 04:35:02,826 : INFO : EPOCH 21 - PROGRESS: at 18.60% examples, 3393836 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:03,828 : INFO : EPOCH 21 - PROGRESS: at 37.80% examples, 3441500 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:04,828 : INFO : EPOCH 21 - PROGRESS: at 57.08% examples, 3457314 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:05,829 : INFO : EPOCH 21 - PROGRESS: at 76.01% examples, 3465202 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:06,830 : INFO : EPOCH 21 - PROGRESS: at 94.72% examples, 3463351 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:07,116 : INFO : EPOCH 21: training on 24464085 raw words (18307813 effective words) took 5.3s, 3459475 effective words/s\n",
      "2023-04-14 04:35:08,121 : INFO : EPOCH 22 - PROGRESS: at 18.42% examples, 3356825 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:09,121 : INFO : EPOCH 22 - PROGRESS: at 37.24% examples, 3390675 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:10,124 : INFO : EPOCH 22 - PROGRESS: at 56.60% examples, 3427130 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:11,125 : INFO : EPOCH 22 - PROGRESS: at 75.62% examples, 3444370 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:12,127 : INFO : EPOCH 22 - PROGRESS: at 94.64% examples, 3456964 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:12,411 : INFO : EPOCH 22: training on 24464085 raw words (18308838 effective words) took 5.3s, 3459280 effective words/s\n",
      "2023-04-14 04:35:13,415 : INFO : EPOCH 23 - PROGRESS: at 18.70% examples, 3419318 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:14,416 : INFO : EPOCH 23 - PROGRESS: at 38.07% examples, 3469891 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:15,420 : INFO : EPOCH 23 - PROGRESS: at 57.40% examples, 3477208 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:16,421 : INFO : EPOCH 23 - PROGRESS: at 76.59% examples, 3491199 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:17,423 : INFO : EPOCH 23 - PROGRESS: at 95.46% examples, 3491971 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:17,657 : INFO : EPOCH 23: training on 24464085 raw words (18310495 effective words) took 5.2s, 3491622 effective words/s\n",
      "2023-04-14 04:35:18,662 : INFO : EPOCH 24 - PROGRESS: at 18.63% examples, 3404075 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:19,663 : INFO : EPOCH 24 - PROGRESS: at 37.99% examples, 3462241 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:20,664 : INFO : EPOCH 24 - PROGRESS: at 57.40% examples, 3479930 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:21,667 : INFO : EPOCH 24 - PROGRESS: at 76.31% examples, 3478821 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:22,666 : INFO : EPOCH 24 - PROGRESS: at 95.46% examples, 3493615 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:22,896 : INFO : EPOCH 24: training on 24464085 raw words (18307415 effective words) took 5.2s, 3496347 effective words/s\n",
      "2023-04-14 04:35:23,898 : INFO : EPOCH 25 - PROGRESS: at 18.83% examples, 3450219 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:24,900 : INFO : EPOCH 25 - PROGRESS: at 38.29% examples, 3486073 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:25,902 : INFO : EPOCH 25 - PROGRESS: at 57.48% examples, 3485082 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:26,903 : INFO : EPOCH 25 - PROGRESS: at 76.71% examples, 3499744 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:27,905 : INFO : EPOCH 25 - PROGRESS: at 95.60% examples, 3499680 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:28,128 : INFO : EPOCH 25: training on 24464085 raw words (18310818 effective words) took 5.2s, 3500675 effective words/s\n",
      "2023-04-14 04:35:29,133 : INFO : EPOCH 26 - PROGRESS: at 18.63% examples, 3402345 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:30,136 : INFO : EPOCH 26 - PROGRESS: at 37.88% examples, 3447715 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:31,136 : INFO : EPOCH 26 - PROGRESS: at 57.21% examples, 3466599 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:32,141 : INFO : EPOCH 26 - PROGRESS: at 76.44% examples, 3482124 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:33,144 : INFO : EPOCH 26 - PROGRESS: at 95.32% examples, 3483684 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:33,386 : INFO : EPOCH 26: training on 24464085 raw words (18308101 effective words) took 5.3s, 3483946 effective words/s\n",
      "2023-04-14 04:35:34,389 : INFO : EPOCH 27 - PROGRESS: at 17.24% examples, 3147734 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:35,391 : INFO : EPOCH 27 - PROGRESS: at 36.73% examples, 3340451 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:36,392 : INFO : EPOCH 27 - PROGRESS: at 56.00% examples, 3394115 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:37,392 : INFO : EPOCH 27 - PROGRESS: at 75.04% examples, 3415781 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:38,393 : INFO : EPOCH 27 - PROGRESS: at 93.95% examples, 3433058 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:38,711 : INFO : EPOCH 27: training on 24464085 raw words (18307693 effective words) took 5.3s, 3440170 effective words/s\n",
      "2023-04-14 04:35:39,715 : INFO : EPOCH 28 - PROGRESS: at 18.13% examples, 3298712 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:40,715 : INFO : EPOCH 28 - PROGRESS: at 36.88% examples, 3353819 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:41,716 : INFO : EPOCH 28 - PROGRESS: at 56.30% examples, 3410462 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:42,720 : INFO : EPOCH 28 - PROGRESS: at 75.37% examples, 3428599 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:43,721 : INFO : EPOCH 28 - PROGRESS: at 94.18% examples, 3439078 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:44,031 : INFO : EPOCH 28: training on 24464085 raw words (18308684 effective words) took 5.3s, 3442385 effective words/s\n",
      "2023-04-14 04:35:45,034 : INFO : EPOCH 29 - PROGRESS: at 18.53% examples, 3383345 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:46,034 : INFO : EPOCH 29 - PROGRESS: at 37.72% examples, 3437067 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:47,036 : INFO : EPOCH 29 - PROGRESS: at 57.00% examples, 3453759 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:48,039 : INFO : EPOCH 29 - PROGRESS: at 76.19% examples, 3474203 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:49,039 : INFO : EPOCH 29 - PROGRESS: at 94.93% examples, 3473169 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:49,297 : INFO : EPOCH 29: training on 24464085 raw words (18305850 effective words) took 5.3s, 3478091 effective words/s\n",
      "2023-04-14 04:35:50,299 : INFO : EPOCH 30 - PROGRESS: at 18.53% examples, 3383878 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:51,301 : INFO : EPOCH 30 - PROGRESS: at 37.84% examples, 3448117 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:52,301 : INFO : EPOCH 30 - PROGRESS: at 57.08% examples, 3459220 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:53,302 : INFO : EPOCH 30 - PROGRESS: at 76.09% examples, 3470833 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:54,303 : INFO : EPOCH 30 - PROGRESS: at 95.08% examples, 3480907 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:54,561 : INFO : EPOCH 30: training on 24464085 raw words (18307704 effective words) took 5.3s, 3478572 effective words/s\n",
      "2023-04-14 04:35:55,565 : INFO : EPOCH 31 - PROGRESS: at 18.70% examples, 3420030 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:56,567 : INFO : EPOCH 31 - PROGRESS: at 37.99% examples, 3460461 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:57,571 : INFO : EPOCH 31 - PROGRESS: at 57.18% examples, 3461347 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:58,574 : INFO : EPOCH 31 - PROGRESS: at 76.09% examples, 3465317 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:59,575 : INFO : EPOCH 31 - PROGRESS: at 94.70% examples, 3458155 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:35:59,862 : INFO : EPOCH 31: training on 24464085 raw words (18307721 effective words) took 5.3s, 3455168 effective words/s\n",
      "2023-04-14 04:36:00,867 : INFO : EPOCH 32 - PROGRESS: at 18.56% examples, 3386967 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:01,869 : INFO : EPOCH 32 - PROGRESS: at 37.27% examples, 3393010 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:02,869 : INFO : EPOCH 32 - PROGRESS: at 56.00% examples, 3392562 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:03,870 : INFO : EPOCH 32 - PROGRESS: at 74.95% examples, 3410410 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:04,872 : INFO : EPOCH 32 - PROGRESS: at 93.70% examples, 3422814 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:05,196 : INFO : EPOCH 32: training on 24464085 raw words (18308709 effective words) took 5.3s, 3434198 effective words/s\n",
      "2023-04-14 04:36:06,200 : INFO : EPOCH 33 - PROGRESS: at 18.63% examples, 3403534 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:07,201 : INFO : EPOCH 33 - PROGRESS: at 37.91% examples, 3456256 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:08,201 : INFO : EPOCH 33 - PROGRESS: at 57.18% examples, 3466896 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:09,205 : INFO : EPOCH 33 - PROGRESS: at 75.94% examples, 3461445 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:10,206 : INFO : EPOCH 33 - PROGRESS: at 94.85% examples, 3468792 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:10,475 : INFO : EPOCH 33: training on 24464085 raw words (18311544 effective words) took 5.3s, 3470589 effective words/s\n",
      "2023-04-14 04:36:11,478 : INFO : EPOCH 34 - PROGRESS: at 18.63% examples, 3404515 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:12,481 : INFO : EPOCH 34 - PROGRESS: at 38.03% examples, 3464403 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:13,484 : INFO : EPOCH 34 - PROGRESS: at 57.44% examples, 3479629 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:14,486 : INFO : EPOCH 34 - PROGRESS: at 76.28% examples, 3475135 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:15,486 : INFO : EPOCH 34 - PROGRESS: at 95.15% examples, 3480545 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:15,739 : INFO : EPOCH 34: training on 24464085 raw words (18309293 effective words) took 5.3s, 3480000 effective words/s\n",
      "2023-04-14 04:36:16,741 : INFO : EPOCH 35 - PROGRESS: at 18.60% examples, 3399369 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:17,741 : INFO : EPOCH 35 - PROGRESS: at 37.55% examples, 3423590 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:18,745 : INFO : EPOCH 35 - PROGRESS: at 57.00% examples, 3452125 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:19,745 : INFO : EPOCH 35 - PROGRESS: at 75.86% examples, 3458311 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:20,747 : INFO : EPOCH 35 - PROGRESS: at 94.89% examples, 3470438 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:21,011 : INFO : EPOCH 35: training on 24464085 raw words (18305999 effective words) took 5.3s, 3473547 effective words/s\n",
      "2023-04-14 04:36:22,014 : INFO : EPOCH 36 - PROGRESS: at 18.49% examples, 3375804 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:23,016 : INFO : EPOCH 36 - PROGRESS: at 37.64% examples, 3427731 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:24,017 : INFO : EPOCH 36 - PROGRESS: at 57.00% examples, 3453663 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:25,017 : INFO : EPOCH 36 - PROGRESS: at 75.70% examples, 3449555 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:26,018 : INFO : EPOCH 36 - PROGRESS: at 94.41% examples, 3450668 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:26,310 : INFO : EPOCH 36: training on 24464085 raw words (18307598 effective words) took 5.3s, 3456488 effective words/s\n",
      "2023-04-14 04:36:27,312 : INFO : EPOCH 37 - PROGRESS: at 18.53% examples, 3387252 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:28,313 : INFO : EPOCH 37 - PROGRESS: at 37.76% examples, 3443883 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:29,315 : INFO : EPOCH 37 - PROGRESS: at 57.21% examples, 3468951 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:30,315 : INFO : EPOCH 37 - PROGRESS: at 76.40% examples, 3486373 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:31,316 : INFO : EPOCH 37 - PROGRESS: at 95.38% examples, 3492713 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:31,550 : INFO : EPOCH 37: training on 24464085 raw words (18310682 effective words) took 5.2s, 3495632 effective words/s\n",
      "2023-04-14 04:36:32,553 : INFO : EPOCH 38 - PROGRESS: at 18.60% examples, 3398695 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:33,553 : INFO : EPOCH 38 - PROGRESS: at 37.88% examples, 3453235 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:34,554 : INFO : EPOCH 38 - PROGRESS: at 57.04% examples, 3457102 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:35,557 : INFO : EPOCH 38 - PROGRESS: at 75.20% examples, 3422391 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:36,556 : INFO : EPOCH 38 - PROGRESS: at 93.99% examples, 3434571 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:36,875 : INFO : EPOCH 38: training on 24464085 raw words (18308512 effective words) took 5.3s, 3439805 effective words/s\n",
      "2023-04-14 04:36:37,879 : INFO : EPOCH 39 - PROGRESS: at 18.63% examples, 3403744 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:38,879 : INFO : EPOCH 39 - PROGRESS: at 37.60% examples, 3426222 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:39,881 : INFO : EPOCH 39 - PROGRESS: at 56.84% examples, 3443638 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:40,881 : INFO : EPOCH 39 - PROGRESS: at 75.66% examples, 3448724 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:41,881 : INFO : EPOCH 39 - PROGRESS: at 94.56% examples, 3457044 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:42,170 : INFO : EPOCH 39: training on 24464085 raw words (18308376 effective words) took 5.3s, 3459464 effective words/s\n",
      "2023-04-14 04:36:43,174 : INFO : EPOCH 40 - PROGRESS: at 18.53% examples, 3378141 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:44,174 : INFO : EPOCH 40 - PROGRESS: at 37.76% examples, 3439337 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:45,177 : INFO : EPOCH 40 - PROGRESS: at 57.04% examples, 3452957 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:46,179 : INFO : EPOCH 40 - PROGRESS: at 75.94% examples, 3460478 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:47,179 : INFO : EPOCH 40 - PROGRESS: at 94.93% examples, 3472332 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:47,439 : INFO : EPOCH 40: training on 24464085 raw words (18307572 effective words) took 5.3s, 3475807 effective words/s\n",
      "2023-04-14 04:36:48,444 : INFO : EPOCH 41 - PROGRESS: at 18.46% examples, 3362598 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:49,445 : INFO : EPOCH 41 - PROGRESS: at 37.38% examples, 3404988 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:50,446 : INFO : EPOCH 41 - PROGRESS: at 56.72% examples, 3434745 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:51,449 : INFO : EPOCH 41 - PROGRESS: at 74.01% examples, 3365423 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:52,450 : INFO : EPOCH 41 - PROGRESS: at 92.59% examples, 3380306 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:52,851 : INFO : EPOCH 41: training on 24464085 raw words (18308559 effective words) took 5.4s, 3384471 effective words/s\n",
      "2023-04-14 04:36:53,854 : INFO : EPOCH 42 - PROGRESS: at 18.46% examples, 3367658 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:54,854 : INFO : EPOCH 42 - PROGRESS: at 37.76% examples, 3441633 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:55,856 : INFO : EPOCH 42 - PROGRESS: at 56.95% examples, 3450277 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:56,857 : INFO : EPOCH 42 - PROGRESS: at 75.86% examples, 3459399 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:57,857 : INFO : EPOCH 42 - PROGRESS: at 94.53% examples, 3454651 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:36:58,164 : INFO : EPOCH 42: training on 24464085 raw words (18308329 effective words) took 5.3s, 3447390 effective words/s\n",
      "2023-04-14 04:36:59,166 : INFO : EPOCH 43 - PROGRESS: at 17.41% examples, 3176538 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:00,167 : INFO : EPOCH 43 - PROGRESS: at 36.17% examples, 3287600 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:01,169 : INFO : EPOCH 43 - PROGRESS: at 54.79% examples, 3322568 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:02,169 : INFO : EPOCH 43 - PROGRESS: at 73.81% examples, 3360396 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:03,171 : INFO : EPOCH 43 - PROGRESS: at 92.59% examples, 3382797 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:03,563 : INFO : EPOCH 43: training on 24464085 raw words (18309741 effective words) took 5.4s, 3392253 effective words/s\n",
      "2023-04-14 04:37:04,567 : INFO : EPOCH 44 - PROGRESS: at 18.49% examples, 3372798 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:05,569 : INFO : EPOCH 44 - PROGRESS: at 37.64% examples, 3427759 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:06,570 : INFO : EPOCH 44 - PROGRESS: at 56.68% examples, 3432610 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:07,572 : INFO : EPOCH 44 - PROGRESS: at 75.62% examples, 3444619 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:08,572 : INFO : EPOCH 44 - PROGRESS: at 93.85% examples, 3428863 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:08,901 : INFO : EPOCH 44: training on 24464085 raw words (18307371 effective words) took 5.3s, 3431136 effective words/s\n",
      "2023-04-14 04:37:09,907 : INFO : EPOCH 45 - PROGRESS: at 18.60% examples, 3391306 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:10,907 : INFO : EPOCH 45 - PROGRESS: at 37.60% examples, 3424183 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:11,906 : INFO : EPOCH 45 - PROGRESS: at 56.92% examples, 3448647 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:12,909 : INFO : EPOCH 45 - PROGRESS: at 75.70% examples, 3448022 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:13,911 : INFO : EPOCH 45 - PROGRESS: at 94.64% examples, 3456975 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:14,195 : INFO : EPOCH 45: training on 24464085 raw words (18306237 effective words) took 5.3s, 3459928 effective words/s\n",
      "2023-04-14 04:37:15,200 : INFO : EPOCH 46 - PROGRESS: at 18.13% examples, 3293174 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:16,202 : INFO : EPOCH 46 - PROGRESS: at 36.27% examples, 3290296 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:17,205 : INFO : EPOCH 46 - PROGRESS: at 50.30% examples, 3036012 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:18,205 : INFO : EPOCH 46 - PROGRESS: at 66.53% examples, 3021017 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:19,207 : INFO : EPOCH 46 - PROGRESS: at 84.41% examples, 3077219 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:20,046 : INFO : EPOCH 46: training on 24464085 raw words (18307583 effective words) took 5.8s, 3129758 effective words/s\n",
      "2023-04-14 04:37:21,049 : INFO : EPOCH 47 - PROGRESS: at 15.52% examples, 2837133 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:22,053 : INFO : EPOCH 47 - PROGRESS: at 29.41% examples, 2687374 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:23,053 : INFO : EPOCH 47 - PROGRESS: at 47.93% examples, 2892971 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:24,053 : INFO : EPOCH 47 - PROGRESS: at 66.13% examples, 3005061 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:25,054 : INFO : EPOCH 47 - PROGRESS: at 83.87% examples, 3061485 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:25,935 : INFO : EPOCH 47: training on 24464085 raw words (18307017 effective words) took 5.9s, 3110034 effective words/s\n",
      "2023-04-14 04:37:26,940 : INFO : EPOCH 48 - PROGRESS: at 16.74% examples, 3049597 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:27,941 : INFO : EPOCH 48 - PROGRESS: at 35.36% examples, 3211545 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:28,943 : INFO : EPOCH 48 - PROGRESS: at 53.30% examples, 3233169 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:29,945 : INFO : EPOCH 48 - PROGRESS: at 71.52% examples, 3252510 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:30,947 : INFO : EPOCH 48 - PROGRESS: at 90.31% examples, 3292014 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:31,473 : INFO : EPOCH 48: training on 24464085 raw words (18308334 effective words) took 5.5s, 3307318 effective words/s\n",
      "2023-04-14 04:37:32,476 : INFO : EPOCH 49 - PROGRESS: at 18.56% examples, 3387661 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:33,479 : INFO : EPOCH 49 - PROGRESS: at 37.30% examples, 3397152 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:34,479 : INFO : EPOCH 49 - PROGRESS: at 56.41% examples, 3417713 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:35,480 : INFO : EPOCH 49 - PROGRESS: at 75.46% examples, 3437112 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:36,481 : INFO : EPOCH 49 - PROGRESS: at 93.95% examples, 3432589 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-14 04:37:36,803 : INFO : EPOCH 49: training on 24464085 raw words (18310154 effective words) took 5.3s, 3436509 effective words/s\n",
      "2023-04-14 04:37:36,804 : INFO : Word2Vec lifecycle event {'msg': 'training on 1223204250 raw words (915418007 effective words) took 266.1s, 3440652 effective words/s', 'datetime': '2023-04-14T04:37:36.804948', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-04-14 04:37:36,804 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=86314, vector_size=100, alpha=0.025>', 'datetime': '2023-04-14T04:37:36.804948', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "new_w2v_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, workers=4, epochs=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def find_similar_ingredient(ingredient, model, topn=10):\n",
    "    most_similar = model.wv.most_similar(ingredient, topn=topn)\n",
    "    return most_similar if most_similar else None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfind_similar_ingredient\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msausage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_model\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m, in \u001B[0;36mfind_similar_ingredient\u001B[1;34m(ingredient, model, topn)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_similar_ingredient\u001B[39m(ingredient, model, topn\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     most_similar \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwv\u001B[49m\u001B[38;5;241m.\u001B[39mmost_similar(ingredient, topn\u001B[38;5;241m=\u001B[39mtopn)\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m most_similar \u001B[38;5;28;01mif\u001B[39;00m most_similar \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'KeyedVectors' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "find_similar_ingredient('sausage', new_w2v_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 04:37:43,274 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:/Users/01din\\\\Documents/University\\\\BSc thesis\\\\data/nlp\\\\w2v/custom_word2vec_model.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-14T04:37:43.274624', 'gensim': '4.3.0', 'python': '3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "2023-04-14 04:37:43,275 : INFO : not storing attribute cum_table\n",
      "2023-04-14 04:37:43,368 : INFO : saved C:/Users/01din\\Documents/University\\BSc thesis\\data/nlp\\w2v/custom_word2vec_model.model\n"
     ]
    }
   ],
   "source": [
    "new_w2v_model.save(\"C:/Users/01din\\Documents/University\\BSc thesis\\data/nlp\\w2v/custom_word2vec_model.model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"C:/Users/01din\\Documents/University\\BSc thesis\\data/nlp\\w2v/custom_word2vec_model.model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[('kale', 0.7149818539619446),\n ('broccoli', 0.6888524293899536),\n ('chard', 0.641985297203064),\n ('arugula', 0.6373889446258545),\n ('orzo', 0.6292614340782166),\n ('greens', 0.6251826882362366),\n ('artichokes', 0.6160466074943542),\n ('tortellini', 0.6136913299560547),\n ('escarole', 0.6093213558197021),\n ('asparagus', 0.6003960967063904)]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_ingredient('spinach', model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
