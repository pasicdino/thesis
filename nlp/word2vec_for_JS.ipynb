{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "generic = lambda x: literal_eval(x)\n",
    "conv = {'nutrition' : generic, 'steps' : generic, 'ingredients' : generic, 'id_column' : generic, 'jaccard_similarity' : generic, 'diff' : generic, 'recipes' : generic, 'ingredients_original' : generic, 'tags' : generic}\n",
    "df = pd.read_csv(r\"C:\\Users\\01din\\PycharmProjects\\thesis\\data\\cleaned_recipes\\recipes_with_JS.csv\", converters=conv)\n",
    "df.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This was the w2v model that was used to compute the semantic similarity betweeen recipes. After preprocessing, it took all textual entities of the recipe and concatenated them with seperator tokens in between."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#Punctuation, lowercasing, etc.\n",
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if c not in ('!', '.', ':', ',', ';', '?', '(', ')', '[', ']', '{', '}')])\n",
    "    return text\n",
    "\n",
    "#For things like the steps column, which contained lists of strings\n",
    "def preprocess_list(lst):\n",
    "    return ' '.join([preprocess_text(item) for item in lst])\n",
    "\n",
    "#Applying the methods\n",
    "df['combined'] = (\n",
    "    '<name> ' + df['name'].apply(preprocess_text) + ' '\n",
    "    '<ingredients> ' + df['ingredients_original'].apply(preprocess_list) + ' '\n",
    "    '<steps> ' + df['steps'].apply(preprocess_list) + ' '\n",
    "    '<tags> ' + df['tags'].apply(preprocess_list) + ' '\n",
    "    '<description> ' + df['description'].apply(preprocess_text)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "#Tokenize the combined methods with gensims simple_preprocess\n",
    "df['tokenized'] = df['combined'].apply(simple_preprocess)\n",
    "\n",
    "#Make list to train w2v model\n",
    "documents = df['tokenized'].tolist()\n",
    "model = Word2Vec(documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "model.save(r\"C:\\Users\\01din\\PycharmProjects\\thesis\\models\\w2v\\w2v4js.model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\01din\\PycharmProjects\\thesis\\data\\cleaned_recipes\\recipes_with_JS.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
